# The Song Search
## Introduction

Taking inspiration from Shazam, we hope to create a project that would be replicate the inner workings of Shazam and perform a retrieval task on musical data. The core of this IR system comes from finding efficient representations for songs and performing a retrieval task with the said representations. While trying to figure out our plan, we came across the amazing resource Tensorflow Magenta and were intrigued by music transcription models so we decided to explore and experiment with a couple of these models.

## Dataset

1. GTZAN dataset - https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification

2. Curated dataset - https://drive.google.com/drive/folders/11XUyMAMyV0iwJey4IhWVi12GBqw4EdiK?usp=share_link

3. Curated queries - https://drive.google.com/drive/folders/1kmow6vJEt89jmc0NQ1qxYN0To1J5r2KJ?usp=share_link 

## References

- [Hawthorne, Curtis, et al. "Sequence-to-sequence piano transcription with Transformers." *arXiv preprint arXiv:2107.09142* (2021).](https://archives.ismir.net/ismir2021/paper/000030.pdf)
- [Gardner, Josh, et al. "Mt3: Multi-task multitrack music transcription." *arXiv preprint arXiv:2111.03017* (2021).](https://arxiv.org/abs/2111.03017)
- [https://magenta.tensorflow.org/transcription-with-transformers](https://magenta.tensorflow.org/transcription-with-transformers) (the original blog)
- [https://github.com/magenta/mt3](https://github.com/magenta/mt3)
- [https://github.com/google-research/text-to-text-transfer-transformer/](https://github.com/google-research/text-to-text-transfer-transformer/) (T5)

## Authors
For further details please reach out to:
1. Isha Hemant Arora (arora.isha@northeastern.edu)
2. Praveen Kumar Sridhar (sridhar.p@northeastern.edu)
