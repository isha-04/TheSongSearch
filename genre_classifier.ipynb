{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "XM2aieOVvW_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install note-seq"
      ],
      "metadata": {
        "id": "H_MqRwIQ4ZJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import note_seq"
      ],
      "metadata": {
        "id": "q8z0vKlyvo-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.utils import losses_utils\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "metadata": {
        "id": "V1q4PEM-8vut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "1M7UA-BCdc49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/gdrive/MyDrive/genres_original'\n",
        "JSON_PATH = '/content/gdrive/MyDrive/data.json'"
      ],
      "metadata": {
        "id": "BHZphWPkwNj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_dir = []\n",
        "for file in os.listdir(DATASET_PATH):\n",
        "      list_dir.append(file)"
      ],
      "metadata": {
        "id": "hskeBdpNGMSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_mfcc(dataset_path, json_path, num_mfcc=13):\n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"labels\": [],\n",
        "        \"mfcc\": [],\n",
        "        \"filename\": []\n",
        "    }\n",
        "\n",
        "    # loop through all genre sub-folder\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "        if dirpath is not dataset_path:\n",
        "            # save genre label (i.e., sub-folder name) in the mapping\n",
        "            semantic_label = dirpath.split(\"/\")[-1]\n",
        "            if semantic_label in list_dir:\n",
        "                data[\"mapping\"].append(semantic_label)\n",
        "                print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "                # process all audio files in genre sub-dir\n",
        "                for f in filenames:\n",
        "\n",
        "                    # load audio file\n",
        "                    file_path = os.path.join(dirpath, f)\n",
        "                    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "                    mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc)\n",
        "                    mfcc = mfcc.T\n",
        "\n",
        "                    data[\"mfcc\"].append(mfcc.tolist())\n",
        "                    data[\"labels\"].append(i-1)\n",
        "                    data[\"filename\"].append(f)\n",
        "                    \n",
        "    # save MFCCs to json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "    \n",
        "    return data"
      ],
      "metadata": {
        "id": "H7UW6H3Nu5L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = save_mfcc(DATASET_PATH, JSON_PATH)"
      ],
      "metadata": {
        "id": "FlQwVX5Mzxvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/MyDrive/data.json\", \"r\") as fp:\n",
        "    data = json.load(fp)"
      ],
      "metadata": {
        "id": "TTe26byOgVkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape_array = np.array(data['mfcc'][0]).shape"
      ],
      "metadata": {
        "id": "Du-poYw_T5D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove = []\n",
        "\n",
        "for i, d in enumerate(data['mfcc']):\n",
        "    if np.array(d).shape != shape_array:\n",
        "        remove.append(i)"
      ],
      "metadata": {
        "id": "_sTpYCR8b2pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in sorted(remove, reverse=True):\n",
        "    del data['mfcc'][index]\n",
        "    del data['labels'][index]\n",
        "    del data['filename'][index]"
      ],
      "metadata": {
        "id": "dVCCNDGSflSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"labels\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
      ],
      "metadata": {
        "id": "IPIFI8jvAcVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR2xJ7Ii8qXo"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([    \n",
        "    keras.layers.LSTM(128, return_sequences=True, input_shape=[None, 13]),\n",
        "    keras.layers.LayerNormalization(),\n",
        "    keras.layers.LSTM(64, return_sequences=True),\n",
        "    keras.layers.LayerNormalization(),\n",
        "    keras.layers.LSTM(32),\n",
        "    keras.layers.Dense(10 ,  activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss ='sparse_categorical_crossentropy', \n",
        "    optimizer = keras.optimizers.Adam() , \n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(\n",
        "    monitor='val_accuracy', restore_best_weights=True, patience=8, min_delta = 0.001\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=100)"
      ],
      "metadata": {
        "id": "6j6o3T2O9zm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func = K.function([model.input], [model.layers[-2].output])\n",
        "outputs = func(X)\n",
        "VECTORS = outputs[0]"
      ],
      "metadata": {
        "id": "XxsyAbiHowk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_path = '/content/gdrive/MyDrive/query/'\n",
        "query_use = '/content/gdrive/MyDrive/query_output'\n",
        "\n",
        "query_names = os.listdir(query_path)\n",
        "query_rel = os.listdir(query_use)"
      ],
      "metadata": {
        "id": "c00HPWxn1A2P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_rel_name = []\n",
        "\n",
        "for rel in query_rel:\n",
        "    query_rel_name.append(rel.split('.')[0])"
      ],
      "metadata": {
        "id": "M9jKGdOK1IDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_list = []\n",
        "THRESH = 0.95\n",
        "output = []\n",
        "\n",
        "def similarity(query_vec):\n",
        "    for i, vec in enumerate(VECTORS):\n",
        "        vec = vec.reshape((1, vec.shape[0]))\n",
        "        matching_results = cosine_similarity(vec , query_vec).tolist()[0][0]\n",
        "        if matching_results > THRESH:\n",
        "            output.append((data['filename'][i], matching_results))\n",
        "\n",
        "for query_file in tqdm(os.listdir(query_path)):\n",
        "    if query_file.split('.')[0] in query_rel_name:\n",
        "        print(query_file)\n",
        "        signal, sample_rate = librosa.load(os.path.join(query_path, query_file), sr=SAMPLE_RATE)\n",
        "        mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=13)\n",
        "        mfcc_query = mfcc.T\n",
        "        mfcc_query = mfcc_query.reshape((1, mfcc_query.shape[0], mfcc_query.shape[1]))\n",
        "        query_vec = func(mfcc_query)[0]\n",
        "        output_val = similarity(query_vec)\n",
        "        output_list.append((query_file,output))"
      ],
      "metadata": {
        "id": "mTbM233z1NCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_indexes = []\n",
        "for query_file, output in output_list:    \n",
        "    query_file = '.'.join(query_file.split('_')[:2]) + '.wav'\n",
        "    print('-'*30)\n",
        "    print(f'QUERY:  {query_file}')\n",
        "    print(f'BEST MATCHES ARE: {output}')\n",
        "    outlist = [tup[0] for tup in output]\n",
        "    best_match_index = outlist.index(query_file) if query_file in outlist else -1\n",
        "    print(f'CORRECT OUTPUT IN INDEX: {best_match_index}')\n",
        "    output_indexes.append(best_match_index)"
      ],
      "metadata": {
        "id": "ZUX-OgCm1Swm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}